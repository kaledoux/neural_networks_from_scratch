{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20bc080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nnfs.datasets import spiral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50670991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.29492021e-03  4.90500031e-04  5.25418651e-04]\n",
      " [ 3.22723240e-03  1.09349577e-03 -9.29102124e-04]\n",
      " [-1.90558519e-03  3.59558375e-05 -2.26749433e-03]\n",
      " [-8.73713873e-03 -2.59917682e-03  1.02285296e-03]\n",
      " [-1.04359003e-02 -3.17155977e-03  1.49863412e-03]\n",
      " [ 1.16580360e-02  2.21692639e-03  3.80431760e-03]\n",
      " [ 1.79770080e-02  4.24070787e-03  2.46973707e-03]\n",
      " [ 6.94509644e-03  3.08835910e-03 -5.03655394e-03]\n",
      " [-2.22100438e-02 -5.02802177e-03 -3.92401592e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.62525104e-03 -6.42468555e-04 -2.64891644e-04]\n",
      " [-4.52643629e-03 -1.32278129e-03  4.31703037e-04]\n",
      " [ 6.89261894e-03  1.47440902e-03  1.57297615e-03]\n",
      " [ 8.67653262e-03  2.58983492e-03 -1.05164970e-03]\n",
      " [ 1.73847003e-03  1.31624313e-03 -3.50481524e-03]\n",
      " [-9.87512232e-03 -1.65630448e-03 -4.13793481e-03]\n",
      " [-1.76707644e-02 -4.08806258e-03 -2.75984427e-03]\n",
      " [-9.42213854e-03 -3.64232017e-03  4.57080524e-03]\n",
      " [ 2.33814477e-02  5.60568700e-03  2.84000764e-03]]\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.29492021e-03 4.90500031e-04 5.25418651e-04]\n",
      " [3.22723240e-03 1.09349577e-03 0.00000000e+00]\n",
      " [0.00000000e+00 3.59558375e-05 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.02285296e-03]\n",
      " [0.00000000e+00 0.00000000e+00 1.49863412e-03]\n",
      " [1.16580360e-02 2.21692639e-03 3.80431760e-03]\n",
      " [1.79770080e-02 4.24070787e-03 2.46973707e-03]\n",
      " [6.94509644e-03 3.08835910e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.31703037e-04]\n",
      " [6.89261894e-03 1.47440902e-03 1.57297615e-03]\n",
      " [8.67653262e-03 2.58983492e-03 0.00000000e+00]\n",
      " [1.73847003e-03 1.31624313e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.57080524e-03]\n",
      " [2.33814477e-02 5.60568700e-03 2.84000764e-03]]\n"
     ]
    }
   ],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, inputs, neurons):\n",
    "        self.weights = 0.01 * np.random.randn(inputs, neurons)\n",
    "        self.biases = np.zeros(neurons)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights)\n",
    "        \n",
    "\n",
    "class ReluActivation:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        \n",
    "X,y = spiral_data(samples=10, classes=2)\n",
    "\n",
    "dense = DenseLayer(2,3)\n",
    "relu = ReluActivation()\n",
    "\n",
    "dense.forward(X)\n",
    "print(dense.output)\n",
    "\n",
    "relu.forward(dense.output)\n",
    "print(relu.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a72c0038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Dense Layer forward pass: \n",
      " [[ 0.          0.          0.        ]\n",
      " [ 0.00082682  0.00021483  0.00024916]\n",
      " [-0.00340256 -0.00376422  0.00140004]\n",
      " [-0.00289006 -0.00119987 -0.00049285]\n",
      " [ 0.00334626  0.00629187 -0.0035579 ]\n",
      " [ 0.00849454  0.00946884 -0.00355538]\n",
      " [ 0.00737572  0.00472897 -0.00014583]\n",
      " [-0.00895528 -0.01321021  0.00646638]\n",
      " [-0.01216394 -0.01029762  0.00234465]\n",
      " [ 0.00544059  0.01235129 -0.00757125]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.0011353   0.00179779 -0.00092341]\n",
      " [ 0.00164082  0.00311929 -0.00177332]\n",
      " [ 0.00228785  0.00039122  0.00086058]\n",
      " [-0.00304172 -0.0060372   0.00350185]\n",
      " [-0.00850142 -0.00943719  0.00352514]\n",
      " [ 0.00623135  0.01037966 -0.0054996 ]\n",
      " [ 0.01061813  0.01389531 -0.00617838]\n",
      " [ 0.01109382  0.00834721 -0.00125881]\n",
      " [ 0.00025265 -0.00667417  0.00575182]\n",
      " [ 0.          0.          0.        ]\n",
      " [-0.00010794 -0.00088652  0.0006904 ]\n",
      " [-0.00321774 -0.00295208  0.00081227]\n",
      " [ 0.00420697  0.00584503 -0.00273391]\n",
      " [ 0.00681973  0.00737035 -0.00265937]\n",
      " [-0.00088079 -0.00478678  0.00357286]\n",
      " [-0.00320369 -0.00784644  0.00494118]\n",
      " [-0.01143641 -0.01076313  0.00311509]\n",
      " [-0.00508257  0.0002602  -0.00286283]\n",
      " [ 0.01280888  0.01761142 -0.00816824]] \n",
      "\n",
      "After Relu activation: \n",
      " [[0.         0.         0.        ]\n",
      " [0.00082682 0.00021483 0.00024916]\n",
      " [0.         0.         0.00140004]\n",
      " [0.         0.         0.        ]\n",
      " [0.00334626 0.00629187 0.        ]\n",
      " [0.00849454 0.00946884 0.        ]\n",
      " [0.00737572 0.00472897 0.        ]\n",
      " [0.         0.         0.00646638]\n",
      " [0.         0.         0.00234465]\n",
      " [0.00544059 0.01235129 0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.0011353  0.00179779 0.        ]\n",
      " [0.00164082 0.00311929 0.        ]\n",
      " [0.00228785 0.00039122 0.00086058]\n",
      " [0.         0.         0.00350185]\n",
      " [0.         0.         0.00352514]\n",
      " [0.00623135 0.01037966 0.        ]\n",
      " [0.01061813 0.01389531 0.        ]\n",
      " [0.01109382 0.00834721 0.        ]\n",
      " [0.00025265 0.         0.00575182]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.0006904 ]\n",
      " [0.         0.         0.00081227]\n",
      " [0.00420697 0.00584503 0.        ]\n",
      " [0.00681973 0.00737035 0.        ]\n",
      " [0.         0.         0.00357286]\n",
      " [0.         0.         0.00494118]\n",
      " [0.         0.         0.00311509]\n",
      " [0.         0.0002602  0.        ]\n",
      " [0.01280888 0.01761142 0.        ]] \n",
      "\n",
      "After Softmax activation: \n",
      " [[0.33333333 0.33333333 0.33333333]\n",
      " [0.33346553 0.33326151 0.33327296]\n",
      " [0.33317774 0.33317774 0.33364453]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33337675 0.3343602  0.33226305]\n",
      " [0.33416694 0.33449268 0.33134037]\n",
      " [0.33444725 0.33356322 0.33198953]\n",
      " [0.33261407 0.33261407 0.33477185]\n",
      " [0.33307271 0.33307271 0.33385457]\n",
      " [0.33316577 0.33547615 0.33135807]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33338578 0.33360672 0.3330075 ]\n",
      " [0.3333511  0.33384432 0.33280458]\n",
      " [0.33370275 0.33307044 0.33322681]\n",
      " [0.33294401 0.33294401 0.33411198]\n",
      " [0.33294142 0.33294142 0.33411716]\n",
      " [0.33356183 0.33494842 0.33148975]\n",
      " [0.33414412 0.33524097 0.33061491]\n",
      " [0.33487099 0.33395249 0.33117652]\n",
      " [0.33274972 0.33266567 0.33458461]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33325661 0.33325661 0.33348677]\n",
      " [0.33324307 0.33324307 0.33351386]\n",
      " [0.33361788 0.33416481 0.33221731]\n",
      " [0.33402875 0.33421273 0.33175852]\n",
      " [0.33293611 0.33293611 0.33412778]\n",
      " [0.33278386 0.33278386 0.33443228]\n",
      " [0.33298703 0.33298703 0.33402593]\n",
      " [0.33330442 0.33339116 0.33330442]\n",
      " [0.33421489 0.33582383 0.32996127]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LayerDense:\n",
    "    def __init__(self, inputs, neurons):\n",
    "        self.weights = 0.01 * np.random.randn(inputs, neurons)\n",
    "        self.biases = np.zeros(neurons)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        \n",
    "class Relu:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        \n",
    "class Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp = np.exp(inputs - np.max(inputs, axis = 1, keepdims = True))\n",
    "        probs = exp / np.sum(exp, axis = 1, keepdims = True)\n",
    "        self.output = probs\n",
    "        \n",
    "X,y = spiral_data(samples=10, classes=3)\n",
    "dense = LayerDense(2,3)\n",
    "dense.forward(X)\n",
    "print(\"After Dense Layer forward pass: \\n\", dense.output, \"\\n\")\n",
    "activation = Relu()\n",
    "activation.forward(dense.output)\n",
    "print(\"After Relu activation: \\n\", activation.output, \"\\n\")\n",
    "output = Softmax()\n",
    "output.forward(activation.output)\n",
    "print(\"After Softmax activation: \\n\", output.output, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea0135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
